{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1a298d-7e6b-451d-bb9e-45d8558e592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from utils.batching.batch_races import batch_races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8712e937-c3e1-4749-8a2b-1c29d44dbc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded dataset: (2024, 109)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle('data/processed/2025/03/model_ready_train.pkl')\n",
    "print(f\"✅ Loaded dataset: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f63cb4dd-ab2c-4aec-9c3c-5d04d6c173cd",
   "metadata": {},
   "source": [
    "INITIALIZE INPUT FEATURES AND PREPARE/FILTER BATCHES FOR INGESTION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a52861-55b7-41ac-b304-b7312538ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Float features: 63\n",
      "🔢 Embedding indices: ['country_idx', 'going_idx', 'sex_idx', 'type_idx', 'class_label_idx', 'headgear_idx', 'race_class_idx', 'venue_idx']\n",
      "🧠 NLP fields: ['comment_vector', 'spotlight_vector']\n"
     ]
    }
   ],
   "source": [
    "# ✅ STEP 2: Define input feature columns.\n",
    "\n",
    "# ⚙️ Continuous features (numerical signals).\n",
    "float_cols = [\n",
    "    \"distance_f\", \"field_size\", \"class_num\", \"draw\", \"age\", \"or\", \"rpr\", \"ts\", \"lbs\",\n",
    "    \"trainer_ovr_runs\", \"trainer_ovr_wins\", \"trainer_ovr_win_pct\", \"trainer_ovr_profit\",\n",
    "    \"trainer_last_14_runs\", \"trainer_last_14_wins\", \"trainer_last_14_win_pct\", \"trainer_last_14_profit\",\n",
    "    \"jockey_ovr_runs\", \"jockey_ovr_wins\", \"jockey_ovr_win_pct\", \"jockey_ovr_profit\",\n",
    "    \"jockey_last_14_runs\", \"jockey_last_14_wins\", \"jockey_last_14_win_pct\", \"jockey_last_14_profit\",\n",
    "    \"rpr_rank\", \"or_rank\", \"rpr_zscore\", \"or_zscore\"\n",
    "]\n",
    "\n",
    "# ➕ NLP-derived boolean flags.\n",
    "nlp_flags = [c for c in df_train.columns if c.startswith(\"mentions_\")]\n",
    "float_cols += nlp_flags\n",
    "\n",
    "# 🔢 Categorical embeddings (integers).\n",
    "idx_cols = [\n",
    "    \"country_idx\", \"going_idx\", \"sex_idx\", \"type_idx\",\n",
    "    \"class_label_idx\", \"headgear_idx\", \"race_class_idx\", \"venue_idx\"\n",
    "]\n",
    "\n",
    "# 💬 Text embeddings (vector arrays).\n",
    "nlp_cols = [\"comment_vector\", \"spotlight_vector\"]\n",
    "\n",
    "print(f\"📊 Float features: {len(float_cols)}\")\n",
    "print(f\"🔢 Embedding indices: {idx_cols}\")\n",
    "print(f\"🧠 NLP fields: {nlp_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af14a583-ad07-4167-862a-26c492a7f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Batches created: 203\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "📦 float_features shape: (22, 63)\n",
      "🎯 winner_flag shape: (22,)\n"
     ]
    }
   ],
   "source": [
    "batches = batch_races(\n",
    "    df_train,\n",
    "    float_cols=float_cols,\n",
    "    idx_cols=idx_cols,\n",
    "    nlp_cols=nlp_cols,\n",
    "    exclude_non_runners=True,\n",
    "    label_col=\"winner_flag\",\n",
    "    min_runners=5\n",
    ")\n",
    "print(f\"📦 Batches created: {len(batches)}\")\n",
    "\n",
    "print(batches[0][\"winner_flag\"])  # 🎯 Now included!\n",
    "\n",
    "\n",
    "# Peek at shape of batch 0\n",
    "batch = batches[0]\n",
    "print(f\"📦 float_features shape: {batch['float_features'].shape}\")\n",
    "print(f\"🎯 winner_flag shape: {batch['winner_flag'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345bf04b-04ed-47c1-a2d7-0cebc38e7e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏇 Batch 0, #horses: 22 → Winner at index: 2\n",
      "🏇 Batch 1, #horses: 21 → Winner at index: 3\n",
      "🏇 Batch 2, #horses: 9 → Winner at index: 7\n",
      "🏇 Batch 3, #horses: 9 → Winner at index: 2\n",
      "🏇 Batch 4, #horses: 17 → Winner at index: 7\n",
      "🏇 Batch 5, #horses: 18 → Winner at index: 5\n",
      "🏇 Batch 6, #horses: 10 → Winner at index: 6\n",
      "🏇 Batch 7, #horses: 16 → Winner at index: 6\n",
      "🏇 Batch 8, #horses: 19 → Winner at index: 3\n",
      "🏇 Batch 9, #horses: 6 → Winner at index: 3\n"
     ]
    }
   ],
   "source": [
    "# This sanity check ensures the winner is placed in different indices.\n",
    "for i in range(10):\n",
    "    winner_vector = batches[i][\"winner_flag\"]\n",
    "    print(f\"🏇 Batch {i}, #horses: {len(winner_vector)} → Winner at index: {int(winner_vector.argmax())}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba4c952b-db5c-46c9-b63d-612863f8a9ac",
   "metadata": {},
   "source": [
    "PREPARE BATCHES FOR PYTORCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcc103f-7e0a-43bd-b7ee-7cfb4e506581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 63])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# Import our custom PyTorch dataset that wraps batches of races.\n",
    "# This turns the batches into a PyTorch-friendly object.\n",
    "from utils.training.dataloader_utils import RaceDataset\n",
    "\n",
    "# Brings in PyTorches DataLoader, which handles:\n",
    "# - Mini-batching.\n",
    "# - Shuffling.\n",
    "# - Efficient iteration over the dataset.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Wraps the list of race batches in the RaceDataset class.\n",
    "# 'include_target=true' tells it to return 'winner_flag' for training.\n",
    "train_dataset = RaceDataset(batches, include_target=True)\n",
    "\n",
    "# Creates a PyTorch DataLoader that:\n",
    "# - Loads batches ONE RACE AT A TIME (batch_size=1).\n",
    "# Shuffles the order of races (not the horses within them).\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Peek at a batch.\n",
    "\n",
    "# Pull the first batch from the dataset.\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Print the first batch details.\n",
    "print(batch[\"float_feats\"].shape)   # [B, R, F]\n",
    "print(batch[\"targets\"].shape)      # [B, R]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7143bc71-da91-49ae-84a5-61fc1667ef29",
   "metadata": {},
   "source": [
    "INITIALIZE TRAINING LOOP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72086ddb-fcdf-4d6e-94b7-7cda1555528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label_encoders.\n",
    "import joblib\n",
    "\n",
    "label_encoders = joblib.load(\"data/processed/2025/03/embedding_encoders_march-2025.pkl\")\n",
    "\n",
    "# For model setup:\n",
    "#idx_vocab_sizes = [len(le.classes_) for le in label_encoders.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12082082-2aba-426f-bf91-023ad9294334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RaceTransformer(\n",
       "  (heads): EmbeddingHeads(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(9, 32)\n",
       "      (1): Embedding(10, 32)\n",
       "      (2): Embedding(5, 32)\n",
       "      (3): Embedding(4, 32)\n",
       "      (4): Embedding(2, 32)\n",
       "      (5): Embedding(18, 32)\n",
       "      (6): Embedding(7, 32)\n",
       "      (7): Embedding(33, 32)\n",
       "    )\n",
       "    (proj_float): Linear(in_features=63, out_features=32, bias=True)\n",
       "    (proj_comment): Linear(in_features=384, out_features=32, bias=True)\n",
       "    (proj_spotlight): Linear(in_features=384, out_features=32, bias=True)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=352, out_features=352, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=352, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=352, bias=True)\n",
       "        (norm1): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((352,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Sequential(\n",
       "    (0): Linear(in_features=352, out_features=352, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=352, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling.transformer_model import RaceTransformer\n",
    "\n",
    "model = RaceTransformer(\n",
    "    label_encoders=label_encoders,\n",
    "    float_dim=63,\n",
    "    embedding_dim=32,\n",
    "    nlp_dim=384,\n",
    "    hidden_dim=128,\n",
    "    nhead=4,\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f42d7cac-3cdf-4dc4-a30b-7183e3eed0ee",
   "metadata": {},
   "source": [
    "TRAIN THE TRANSFORMER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7381384-fe20-4374-9450-042ddf89703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Saving checkpoints to: checkpoints/transformer_2025-04-04T19-08-35\n",
      "💾 Checkpoints will be saved at epochs: [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 1/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 37.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 1 — Loss: 0.3672 — ⏱️ 5.5s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 2/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 2 — Loss: 0.3559 — ⏱️ 5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 3/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 3 — Loss: 0.3494 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 4/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 4 — Loss: 0.3485 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 5/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 5 — Loss: 0.3452 — ⏱️ 6.3s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 6/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 30.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 6 — Loss: 0.3395 — ⏱️ 6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 7/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 7 — Loss: 0.3373 — ⏱️ 6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 8/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 8 — Loss: 0.3334 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 9/50: 100%|█████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 9 — Loss: 0.3231 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 10/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 33.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 10 — Loss: 0.3215 — ⏱️ 6.1s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 11/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 11 — Loss: 0.3185 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 12/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 12 — Loss: 0.3100 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 13/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 13 — Loss: 0.3022 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 14/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 14 — Loss: 0.2953 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 15/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 15 — Loss: 0.2873 — ⏱️ 5.8s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 16/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 16 — Loss: 0.2747 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 17/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 17 — Loss: 0.2672 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 18/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 18 — Loss: 0.2611 — ⏱️ 5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 19/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 19 — Loss: 0.2416 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 20/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 20 — Loss: 0.2382 — ⏱️ 6.0s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 21/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 21 — Loss: 0.2254 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 22/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 22 — Loss: 0.2190 — ⏱️ 5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 23/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 23 — Loss: 0.2156 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 24/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 24 — Loss: 0.2045 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 25/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 25 — Loss: 0.1950 — ⏱️ 5.9s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 26/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 26 — Loss: 0.1835 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 27/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 27 — Loss: 0.1875 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 28/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 28 — Loss: 0.1766 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 29/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 29 — Loss: 0.1658 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 30/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 30 — Loss: 0.1638 — ⏱️ 5.8s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_30.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 31/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 31 — Loss: 0.1664 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 32/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 32 — Loss: 0.1607 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 33/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 33 — Loss: 0.1681 — ⏱️ 5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 34/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 35.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 34 — Loss: 0.1359 — ⏱️ 5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 35/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 35 — Loss: 0.1378 — ⏱️ 5.8s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_35.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 36/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 36 — Loss: 0.1491 — ⏱️ 6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 37/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:10<00:00, 20.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 37 — Loss: 0.1224 — ⏱️ 10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 38/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 31.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 38 — Loss: 0.1057 — ⏱️ 6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 39/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 39 — Loss: 0.1166 — ⏱️ 6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 40/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 40 — Loss: 0.1125 — ⏱️ 6.3s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 41/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 41 — Loss: 0.1079 — ⏱️ 6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 42/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 42 — Loss: 0.1216 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 43/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 43 — Loss: 0.1199 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 44/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 32.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 44 — Loss: 0.1031 — ⏱️ 6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 45/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 45 — Loss: 0.1284 — ⏱️ 6.0s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_45.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 46/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 46 — Loss: 0.1089 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 47/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 47 — Loss: 0.0933 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 48/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 48 — Loss: 0.0696 — ⏱️ 6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 49/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:05<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 49 — Loss: 0.1066 — ⏱️ 5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧠 Epoch 50/50: 100%|████████████████████████████████████████████████████████████████| 203/203 [00:06<00:00, 33.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 50 — Loss: 0.0843 — ⏱️ 6.1s\n",
      "💾 Saved model to: checkpoints/transformer_2025-04-04T19-08-35/epoch_50.pt\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 🕒 Create a timestamped directory for this run's checkpoints\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "checkpoint_dir = f\"checkpoints/transformer_{timestamp}\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📂 Saving checkpoints to: {checkpoint_dir}\")\n",
    "\n",
    "# Create checkpoint folder if missing\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# 🎯 Loss + Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Number of epochs and checkpoints allowed\n",
    "n_epochs = 50\n",
    "max_checkpoints = 10\n",
    "\n",
    "# Calculate which epochs to save\n",
    "save_epochs = set(\n",
    "    [1, n_epochs] +\n",
    "    [math.ceil(i * n_epochs / max_checkpoints) for i in range(1, max_checkpoints)]\n",
    ")\n",
    "print(f\"💾 Checkpoints will be saved at epochs: {sorted(save_epochs)}\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 🔁 Loop through batches with tqdm progress bar\n",
    "    for batch in tqdm(train_loader, desc=f\"🧠 Epoch {epoch+1}/{n_epochs}\"):\n",
    "        logits = model(\n",
    "            batch[\"float_feats\"],\n",
    "            batch[\"idx_feats\"],\n",
    "            batch[\"comment_vecs\"],\n",
    "            batch[\"spotlight_vecs\"],\n",
    "            batch[\"mask\"]\n",
    "        )\n",
    "        targets = batch[\"targets\"]\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # ⏱️ Epoch Summary\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"📉 Epoch {epoch+1} — Loss: {avg_loss:.4f} — ⏱️ {duration:.1f}s\")\n",
    "\n",
    "    # 💾 Save Checkpoint\n",
    "    if (epoch + 1) in save_epochs:\n",
    "        ckpt_path = f\"{checkpoint_dir}/epoch_{epoch+1}.pt\"\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"💾 Saved model to: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908166b-f9f3-4687-adeb-080ee5a023f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sports)",
   "language": "python",
   "name": "sports"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
